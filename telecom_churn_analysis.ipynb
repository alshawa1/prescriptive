{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Telecom Churn Analysis\n",
                "\n",
                "This notebook covers the end-to-end analysis of the telecom churn dataset.\n",
                "\n",
                "**Objective**: Predict churn and prescribe retention strategies with cost analysis.\n",
                "\n",
                "**Sections**:\n",
                "1. **Preprocessing**\n",
                "2. **Feature Engineering**\n",
                "3. **Descriptive Analytics**\n",
                "4. **Predictive Analytics (Modeling)**\n",
                "5. **Prescriptive Analytics (Strategies & Costs)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "sns.set(style=\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Data\n",
                "file_path = 'telecom_churn.csv'\n",
                "\n",
                "try:\n",
                "    df = pd.read_csv(file_path)\n",
                "    print(f\"Data loaded. Shape: {df.shape}\")\n",
                "    display(df.head())\n",
                "except FileNotFoundError:\n",
                "    print(\"File not found. Please check the path.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle Missing Values\n",
                "print(\"Missing values before:\")\n",
                "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
                "\n",
                "df = df.fillna(method='ffill')\n",
                "print(\"Missing values handled.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Outlier Detection (Numerical Columns)\n",
                "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
                "print(\"Checking and capping outliers...\")\n",
                "\n",
                "for col in numerical_cols:\n",
                "    Q1 = df[col].quantile(0.25)\n",
                "    Q3 = df[col].quantile(0.75)\n",
                "    IQR = Q3 - Q1\n",
                "    \n",
                "    lower = Q1 - 1.5 * IQR\n",
                "    upper = Q3 + 1.5 * IQR\n",
                "    \n",
                "    df[col] = np.where(df[col] < lower, lower, df[col])\n",
                "    df[col] = np.where(df[col] > upper, upper, df[col])\n",
                "    \n",
                "print(\"Outliers processed.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Encode Categorical Variables\n",
                "print(\"Encoding categorical variables...\")\n",
                "le = LabelEncoder()\n",
                "categorical_cols = df.select_dtypes(include=['object']).columns\n",
                "\n",
                "for col in categorical_cols:\n",
                "    if 'date' not in col:\n",
                "        df[col] = le.fit_transform(df[col].astype(str))\n",
                "        \n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Engineering New Features\n",
                "if 'calls_made' in df.columns and 'sms_sent' in df.columns:\n",
                "    df['total_interactions'] = df['calls_made'] + df['sms_sent']\n",
                "\n",
                "if 'data_used' in df.columns:\n",
                "    df['data_usage_log'] = np.log1p(df['data_used'].clip(lower=0))\n",
                "    \n",
                "print(\"Features created: total_interactions, data_usage_log\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Descriptive Analytics (Visualizations)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Churn Distribution Plot\n",
                "if 'churn' in df.columns:\n",
                "    plt.figure(figsize=(6, 4))\n",
                "    sns.countplot(x='churn', data=df)\n",
                "    plt.title(\"Distribution of Churn\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Numerical Distributions (Histograms)\n",
                "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
                "cols_to_plot = [c for c in numerical_cols if c not in ['churn', 'customer_id']]\n",
                "\n",
                "if cols_to_plot:\n",
                "    df[cols_to_plot].hist(figsize=(15, 10), bins=20, edgecolor='black')\n",
                "    plt.suptitle(\"Numerical Feature Distributions\")\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation Heatmap\n",
                "plt.figure(figsize=(12, 10))\n",
                "corr = df.corr()\n",
                "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
                "plt.title(\"Feature Correlation Matrix\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Predictive Analytics (Modeling)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Prepare Data (Split & Scale)\n",
                "if 'churn' in df.columns:\n",
                "    X = df.drop(['churn', 'customer_id', 'date_of_registration'], axis=1, errors='ignore')\n",
                "    y = df['churn']\n",
                "\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "    scaler = StandardScaler()\n",
                "    X_train_scaled = scaler.fit_transform(X_train)\n",
                "    X_test_scaled = scaler.transform(X_test)\n",
                "    print(\"Train/Test split done. Data Scaled.\")\n",
                "else:\n",
                "    print(\"Target 'churn' not found!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Logistic Regression Model\n",
                "lr_model = LogisticRegression()\n",
                "lr_model.fit(X_train_scaled, y_train)\n",
                "print(\"Logistic Regression Trained.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Random Forest Model\n",
                "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "rf_model.fit(X_train_scaled, y_train)\n",
                "print(\"Random Forest Trained.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Gradient Boosting Model\n",
                "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
                "gb_model.fit(X_train_scaled, y_train)\n",
                "print(\"Gradient Boosting Trained.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Best Model Selection & Comparison\n",
                "models = {\n",
                "    'Logistic Regression': lr_model,\n",
                "    'Random Forest': rf_model,\n",
                "    'Gradient Boosting': gb_model\n",
                "}\n",
                "\n",
                "best_score = 0\n",
                "best_model_name = \"\"\n",
                "\n",
                "print(f\"{'Model':<25} | {'F1-Score':<10} | {'AUC':<10}\")\n",
                "print(\"-\" * 50)\n",
                "\n",
                "for name, model in models.items():\n",
                "    y_pred = model.predict(X_test_scaled)\n",
                "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
                "    \n",
                "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
                "    auc = roc_auc_score(y_test, y_prob)\n",
                "    \n",
                "    print(f\"{name:<25} | {f1:.4f}     | {auc:.4f}\")\n",
                "    \n",
                "    if f1 > best_score:\n",
                "        best_score = f1\n",
                "        best_model_name = name\n",
                "\n",
                "print(\"-\" * 50)\n",
                "print(f\"\\n>> WINNER: {best_model_name} with F1-Score: {best_score:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Prescriptive Analytics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Markov Chain Analysis\n",
                "# Simulating state transitions to predict long-term customer distribution.\n",
                "df['value_segment'] = pd.qcut(df['estimated_salary'], 3, labels=['Low', 'Medium', 'High'])\n",
                "\n",
                "# Hypothetical Transition Matrix\n",
                "transition_matrix = np.array([\n",
                "    [0.70, 0.10, 0.05, 0.15], # Low\n",
                "    [0.05, 0.80, 0.10, 0.05], # Medium\n",
                "    [0.02, 0.08, 0.88, 0.02], # High\n",
                "    [0.00, 0.00, 0.00, 1.00]  # Churn\n",
                "])\n",
                "states = ['Low', 'Medium', 'High', 'Churn']\n",
                "\n",
                "print(\"Projected Distribution (12 months):\")\n",
                "curr = np.array([0.4, 0.4, 0.2, 0.0])\n",
                "future = curr.dot(np.linalg.matrix_power(transition_matrix, 12))\n",
                "for s, p in zip(states, future):\n",
                "    print(f\"{s}: {p:.2%}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Monte Carlo Simulation (Risk Analysis)\n",
                "cohort_size = 1000\n",
                "avg_revenue = 50 # Assumed average monthly revenue ($)\n",
                "base_churn = 0.15 # Assumed base churn rate\n",
                "runs = 1000\n",
                "results_mc = []\n",
                "\n",
                "for _ in range(runs):\n",
                "    fluctuated_churn = max(0, min(1, np.random.normal(base_churn, 0.02)))\n",
                "    retained = cohort_size * ((1 - fluctuated_churn) ** 12)\n",
                "    results_mc.append(retained * avg_revenue * 12)\n",
                "    \n",
                "print(f\"Expected Annual Revenue (Mean): ${np.mean(results_mc):,.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ADVANCED: AI-Powered Recommendation System (K-Means Clustering)\n",
                "# 1. Train Clustering Model\n",
                "features = ['estimated_salary']\n",
                "if 'data_used' in df.columns: features.append('data_used')\n",
                "if 'calls_made' in df.columns: features.append('calls_made')\n",
                "\n",
                "X_cluster = df[features].copy()\n",
                "kmeans = KMeans(n_clusters=4, random_state=42)\n",
                "clusters = kmeans.fit_predict(X_cluster)\n",
                "df['Cluster'] = clusters\n",
                "\n",
                "# 2. Name Segments\n",
                "cluster_means = df.groupby('Cluster')[features].mean()\n",
                "cluster_names = {}\n",
                "for c_id, row in cluster_means.iterrows():\n",
                "    label = \"Standard User\"\n",
                "    if row.get('data_used', 0) > df['data_used'].mean() * 1.5:\n",
                "        label = \"Heavy Data User\"\n",
                "    elif row.get('estimated_salary', 0) > df['estimated_salary'].mean() * 1.5:\n",
                "        label = \"High Net-Worth\"\n",
                "    elif row.get('data_used', 0) < df['data_used'].mean() * 0.5:\n",
                "        label = \"Low Engagement\"\n",
                "    cluster_names[c_id] = label\n",
                "    \n",
                "df['Segment_Name'] = df['Cluster'].map(cluster_names)\n",
                "\n",
                "# 3. Show Recommendations for Sample High-Risk Customers\n",
                "print(\"AI Recommendations for High-Risk Customers:\\n\")\n",
                "high_churn_sample = df[df['churn'] == 1].head(5)\n",
                "\n",
                "for idx, row in high_churn_sample.iterrows():\n",
                "    seg = row['Segment_Name']\n",
                "    msg = \"\"\n",
                "    if \"Heavy Data\" in seg: msg = \"Strategy: Offer 50% Off Unlimited Data Plan\"\n",
                "    elif \"High Net-Worth\" in seg: msg = \"Strategy: VIP Concierge Service\"\n",
                "    elif \"Low Engagement\" in seg: msg = \"Strategy: Free Recharge (Win-Back)\"\n",
                "    else: msg = \"Strategy: Standard 1-Month Free Service\"\n",
                "    \n",
                "    print(f\"Customer {row['customer_id']} | Segment: {seg} | {msg}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}